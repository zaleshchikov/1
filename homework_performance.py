import torch
from tabulate import tabulate
# Создайте большие матрицы размеров:
# - 64 x 1024 x 1024
# - 128 x 512 x 512
# - 256 x 256 x 256
# Заполните их случайными числами

matrix_1 = torch.rand(64, 1024, 1024)
matrix_2 = torch.rand(128, 512, 512)
matrix_3 = torch.rand(256, 256, 256)  
if torch.cuda.is_available():
    matrix_1_gpu = matrix_1.cuda()
    matrix_2_gpu = matrix_2.cuda()
    matrix_3_gpu = matrix_3.cuda()
# Создайте функцию для измерения времени выполнения операций
# Используйте torch.cuda.Event() для точного измерения на GPU
# Используйте time.time() для измерения на CPU
import time

def timer(operation, device='cuda'):
    if device == 'cuda':
        torch.cuda.synchronize()
        start = torch.cuda.Event(enable_timing=True)
        end = torch.cuda.Event(enable_timing=True)
        
        start.record()
        operation()
        end.record()
        torch.cuda.synchronize()
        return start.elapsed_time(end)
    else:
        start_time = time.time()
        operation()
        return (time.time() - start_time) * 1000
    
# Сравните время выполнения следующих операций на CPU и CUDA:
# - Матричное умножение (torch.matmul)
# - Поэлементное сложение
# - Поэлементное умножение
# - Транспонирование
# - Вычисление суммы всех элементов

# Для каждой операции:
# 1. Измерьте время на CPU
# 2. Измерьте время на GPU (если доступен)
# 3. Вычислите ускорение (speedup)
# 4. Выведите результаты в табличном виде

# Операции для тестирования
def get_operations_for_matrix(
    cpu_tensor: torch.Tensor,
    gpu_tensor: torch.Tensor
):
    return [
        {
            "name": f"Матричное умножение",
            "cpu_op": lambda: torch.matmul(cpu_tensor, cpu_tensor),
            "gpu_op": lambda: torch.matmul(gpu_tensor, gpu_tensor) if gpu_tensor is not None else None
        },
        {
            "name": f"Поэлементное сложение",
            "cpu_op": lambda: cpu_tensor + cpu_tensor,
            "gpu_op": lambda: gpu_tensor + gpu_tensor if gpu_tensor is not None else None
        },
        {
            "name": f"Поэлементное умножение",
            "cpu_op": lambda: cpu_tensor * cpu_tensor,
            "gpu_op": lambda: gpu_tensor * gpu_tensor if gpu_tensor is not None else None
        },
        {
            "name": f"Транспонирование",
            "cpu_op": lambda: cpu_tensor.transpose(1, 2),
            "gpu_op": lambda: gpu_tensor.transpose(1, 2) if gpu_tensor is not None else None
        },
        {
            "name": f"Сумма всех элементов",
            "cpu_op": lambda: cpu_tensor.sum(),
            "gpu_op": lambda: gpu_tensor.sum() if gpu_tensor is not None else None
        }
    ]

operations = get_operations_for_matrix(matrix_1, matrix_1_gpu)

results = []
for op in operations:
    cpu_time = timer(op["cpu_op"], device='cpu')
    gpu_time = timer(op["gpu_op"], device='cuda')
    speedup = cpu_time / gpu_time
    results.append([
        op["name"],
        f"{cpu_time:.2f} мс",
        f"{gpu_time:.2f} мс" if isinstance(gpu_time, float) else gpu_time,
        f"{speedup:.1f}x" if isinstance(speedup, float) else speedup
    ])

headers = ["Операция", "CPU", "GPU", "Ускорение"]
print(tabulate(results, headers=headers, tablefmt="grid"))

# результаты из коллаб
'''
матрица 1
+------------------------+------------+----------+-------------+
| Операция               | CPU        | GPU      | Ускорение   |
+========================+============+==========+=============+
| Матричное умножение    | 1696.28 мс | 47.49 мс | 35.7x       |
+------------------------+------------+----------+-------------+
| Поэлементное сложение  | 144.17 мс  | 2.29 мс  | 62.9x       |
+------------------------+------------+----------+-------------+
| Поэлементное умножение | 141.17 мс  | 2.28 мс  | 61.9x       |
+------------------------+------------+----------+-------------+
| Транспонирование       | 0.04 мс    | 0.02 мс  | 1.8x        |
+------------------------+------------+----------+-------------+
| Сумма всех элементов   | 22.06 мс   | 1.10 мс  | 20.1x       |
+------------------------+------------+----------+-------------+


матрица 2
+------------------------+-----------+----------+-------------+
| Операция               | CPU       | GPU      | Ускорение   |
+========================+===========+==========+=============+
| Матричное умножение    | 355.31 мс | 12.30 мс | 28.9x       |
+------------------------+-----------+----------+-------------+
| Поэлементное сложение  | 72.28 мс  | 1.18 мс  | 61.1x       |
+------------------------+-----------+----------+-------------+
| Поэлементное умножение | 70.73 мс  | 1.18 мс  | 59.9x       |
+------------------------+-----------+----------+-------------+
| Транспонирование       | 0.03 мс   | 0.02 мс  | 1.7x        |
+------------------------+-----------+----------+-------------+
| Сумма всех элементов   | 11.24 мс  | 0.61 мс  | 18.4x       |
+------------------------+-----------+----------+-------------+

матрица 3
+------------------------+-----------+---------+-------------+
| Операция               | CPU       | GPU     | Ускорение   |
+========================+===========+=========+=============+
| Матричное умножение    | 107.90 мс | 3.32 мс | 32.5x       |
+------------------------+-----------+---------+-------------+
| Поэлементное сложение  | 35.92 мс  | 0.63 мс | 56.7x       |
+------------------------+-----------+---------+-------------+
| Поэлементное умножение | 33.86 мс  | 0.62 мс | 54.4x       |
+------------------------+-----------+---------+-------------+
| Транспонирование       | 0.03 мс   | 0.02 мс | 1.4x        |
+------------------------+-----------+---------+-------------+
| Сумма всех элементов   | 5.50 мс   | 0.34 мс | 16.2x       |
+------------------------+-----------+---------+-------------+

так же я создал матрицу 10х10х10 и вот результаты для неё:
+------------------------+---------+---------+-------------+
| Операция               | CPU     | GPU     | Ускорение   |
+========================+=========+=========+=============+
| Матричное умножение    | 6.19 мс | 0.35 мс | 17.7x       |
+------------------------+---------+---------+-------------+
| Поэлементное сложение  | 0.04 мс | 0.06 мс | 0.6x        |
+------------------------+---------+---------+-------------+
| Поэлементное умножение | 0.02 мс | 0.03 мс | 0.6x        |
+------------------------+---------+---------+-------------+
| Транспонирование       | 0.02 мс | 0.02 мс | 1.2x        |
+------------------------+---------+---------+-------------+
| Сумма всех элементов   | 0.03 мс | 0.07 мс | 0.4x        |
+------------------------+---------+---------+-------------+
'''

# Проанализируйте результаты:
# - Какие операции получают наибольшее ускорение на GPU?
#       видно что операции с вычислениями имеют преимущественное ускорение
# - Почему некоторые операции могут быть медленнее на GPU?
#       операции где нет необходимости в большом количестве вычислений могут быть 
#       медленнее из-за более долгой загрузки и получения данных в GPU
# - Как размер матриц влияет на ускорение?
#       больше размер -> больше ускорение. 
#       для совсем небольших матриц использование gpu даже замедляет процесс вычислений.
# - Что происходит при передаче данных между CPU и GPU?
#       данные передаются по каналу или шине с определенной скоростью передачи, скорость передачи много ниже скорости вычисления,
#       именно поэтому для малых матриц использование gpu менее эффективно, хотя там время и так очень маленькое, что 
#       как мне кажется не имеет критического значения, тем более что на больших матрицах ускорение происходит в десятки раз.